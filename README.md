# Deep Learning

Part A: 

• Problem: Use Multilayer Perceptron (MLP) deep learning models to estimate total energy consumption of smart home with weather information.

• Data Set: The data is provided in “PartA-SmartHomeEnergyConsumption.csv” file, which contains the readings of house appliances in kW from smart meters and weather conditions.

• Data Exploration and Preparation: Explore and visualize characteristics of the provided data. Then prepare data for predictive modelling.

• Total Consumption Estimation: Create and perform experiment with MLP models. Report my experimental work and recommend a final (best) MLP mode

Part B: 

• Problem: Use Autoencoder (with CNN) deep learning models to remove noise from low resolution photographs.

• Data Set: The data is CIFAR10, which is available in tensorflow.keras.datasets. 

• Data Exploration and Preparation: Explore and visualize characteristics of the provided data. Then prepare data for image denoising.

• Image Denoising: Create and Experiment with Autoencoder models, select the best model and justify

Part C: 

• Problem: Use Recurrent Neural Network (with LSTM or GRU) deep learning model to forecast the price of a stock.

• Data Set: The data is provided in “PartC-Stocks.csv” file, which contains the daily price of serval stocks. The stock to be forecasted is AAPL.

• Data Exploration and Preparation: Explore and visualize characteristics of the provided data. Then prepare data for multi-variate time series analysis and forecasting.

• Stock Price Forecasting: Create and experiment with the RRN model. Report my experimental work.


## Reflection

Traditional machine learning refers to the process of extraction of knowledge from a large dataset loaded into the machine. Experts formulate the rules and rectify errors made by the machine. Therfore, traditional machine learning approach removes the negative overtraining impact which appears frequently in deep learning.

However there are some advantages can be gained when using Deep Learning approach. Firstly, we can maximize utilization of unstructured data. For instance, you can use deep learning algorithms to uncover any existing relations between industry analysis, social media chatter, and more to predict upcoming stock prices of a given organization. In addition, deep learning could eliminate the need for feature engineering. To be more specific, learn the data to identify the relevant between features and then combine them to promote faster learning without being told to do so explicitly. This ability helps data scientists to save a significant amount of work.

Deep Learning is the force that is bringing autonomous driving to life. A million sets of data are fed to a system to build a model, to train the machines to learn, and then test the results in a safe environment. Besides, The most popular application of deep learning is virtual assistants ranging from Alexa to Siri to Google Assistant. With deep learning applications such as text generation and document summarizations, virtual assistants can assist you in creating or sending appropriate email copy as well.

## Author
- [@Eden Nguyen](https://github.com/giAngNgE)
